{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1v0FgqON4R8n"
   },
   "source": [
    "# Classification with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUfX1FMv4R8w"
   },
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Similar to the regression problem, except that the values $y$ we now want to predict take on only a small number of discrete values.\n",
    "Let's focus on the *binary classification* problem in which $y$ can take on only two values, $0$ and $1$.\n",
    "\n",
    "E.g. if we are trying to build a spam classifier for email, $0$ could mean not spam while $1$, spam.\n",
    "\n",
    "In theory, we could approach the classification problem ignoring the fact that $y$ is discrete-valued, and use linear regression algorithm to predict $y$ given $X$.\n",
    "This will perform poorly, and it doesn't make sense to output values larger than $1$ or smaller than $0$.\n",
    "\n",
    "Logistic Regression uses a different function instead, called *sigmoid function*:\n",
    "\n",
    "$ g(z) = \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-z}} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T18:14:26.792043Z",
     "start_time": "2021-09-14T18:14:26.447815Z"
    },
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1604480815556,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "skWF_J9u4R8z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('retina')\n",
    "matplotlib.rcParams['figure.figsize'] = (12, 8)\n",
    "matplotlib.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T18:14:28.723457Z",
     "start_time": "2021-09-14T18:14:28.211368Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1604480946488,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "U-5-jIDP4R89",
    "outputId": "a939ad74-77e6-4df1-83c0-ca37132a47fa"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 100)\n",
    "y = 1 / ( 1  + np.exp(-x))\n",
    "\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.grid()\n",
    "plt.yticks(np.arange(0.0, 1.1, 0.1))\n",
    "plt.title(\"sigmoid function\")\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"$g(z)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UqiZcQ-4R9E"
   },
   "source": [
    "Notice that $g(z)$ tends towards 1 as $z \\to \\infty$, and $g(z)$ tends towards $0$ as $z \\to -\\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXNyNH6R4R9G"
   },
   "source": [
    "For classification, we can take a threshold, e.g. $0.5$, everything that is above the threshold, is positive, $y = 1$, while the other values mean $y = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faL_MIvM4R9H"
   },
   "source": [
    "## Logistic Regression: Titanic dataset\n",
    "\n",
    "We will use the [Titanic Dataset](https://www.kaggle.com/c/titanic) to illustrate the Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T18:15:10.153810Z",
     "start_time": "2021-09-14T18:15:09.526887Z"
    },
    "executionInfo": {
     "elapsed": 730,
     "status": "ok",
     "timestamp": 1604480965233,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "oFhwVhDm4R9J"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T18:15:41.868212Z",
     "start_time": "2021-09-14T18:15:41.858158Z"
    },
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1604480995482,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "Pm-C5AgS4R9W"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('files/data/titanic.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGycAaWd4R9h"
   },
   "source": [
    "Each line from train/test dataset is a passenger, and each one has a number of features (12).\n",
    "\n",
    "All features are described on the [Kaggle challenge page](https://www.kaggle.com/c/titanic/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1250,
     "status": "ok",
     "timestamp": 1604482091788,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "t8r1H6gb4R9s",
    "outputId": "66241179-0538-4e0b-8b1b-4a2db8344b1c"
   },
   "outputs": [],
   "source": [
    "# Notice the 'object' type of columns\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eo7Xd7JC4R9z"
   },
   "source": [
    "### Data exploration and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJITIZvB4R90"
   },
   "source": [
    "Which features are categorical?\n",
    "\n",
    "Which features are numerical?\n",
    "\n",
    "Which features contain blank, null or empty values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "executionInfo": {
     "elapsed": 799,
     "status": "ok",
     "timestamp": 1604482146828,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "smY-dTtz4R9-",
    "outputId": "00db6b89-1f10-4dd1-d61a-1f584ab9fb60"
   },
   "outputs": [],
   "source": [
    "dataset['Sex'] = dataset['Sex'].map({'male':0, 'female':1})\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titanic = dataset[[\n",
    "    'Pclass',\n",
    "    'Sex',\n",
    "    'Age',\n",
    "    'SibSp',\n",
    "    'Parch',\n",
    "    'Fare',\n",
    "    'Survived' # we will remove this later\n",
    "]].copy()\n",
    "\n",
    "X_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1604482256541,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "uos8R1_K4R-H",
    "outputId": "a572f150-7786-4ffd-8708-54b0adcc74be"
   },
   "outputs": [],
   "source": [
    "X_titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdL6MiTf4R-j"
   },
   "source": [
    "Check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1604482261236,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "1EB2drpl4R-l",
    "outputId": "0b124aa1-c12b-4970-f317-d33a05d2364a"
   },
   "outputs": [],
   "source": [
    "print(\"We have null values: \", X_titanic.isnull().values.any())\n",
    "X_titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titanic['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titanic['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_titanic['Age'].fillna(X_titanic['Age'].mean(), inplace=True)\n",
    "\n",
    "print(\"We have null values: \", X_titanic.isnull().values.any())\n",
    "X_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 919
    },
    "executionInfo": {
     "elapsed": 15240,
     "status": "ok",
     "timestamp": 1604481743525,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "0ntE0r8k4R-Q",
    "outputId": "180a92b6-a7f7-4a80-9d8a-595980846951"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(X_titanic, hue='Survived', palette='tab10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "executionInfo": {
     "elapsed": 1094,
     "status": "ok",
     "timestamp": 1604481877026,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "xQd1ECsX4R-U",
    "outputId": "342587a3-6237-4c09-9243-d44bfba6b3f8"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='Sex', data=X_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "executionInfo": {
     "elapsed": 844,
     "status": "ok",
     "timestamp": 1604481879667,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "3uRTO-br4R-X",
    "outputId": "328f48a9-6902-4bfd-80cb-1f51e29b9cde"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='Survived', data=X_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "executionInfo": {
     "elapsed": 568,
     "status": "ok",
     "timestamp": 1604481903148,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "8nK5UPyh4R-g",
    "outputId": "bfefa49d-ad8b-475a-9ced-c5b04e4cf7fa"
   },
   "outputs": [],
   "source": [
    "X_titanic[X_titanic['Survived'] == 1.0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 613,
     "status": "ok",
     "timestamp": 1604481937442,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "lZ-ewZRE1ug8"
   },
   "outputs": [],
   "source": [
    "y_titanic = X_titanic['Survived'].copy()\n",
    "X_titanic.drop(['Survived'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 842,
     "status": "ok",
     "timestamp": 1604482267965,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "bGqFVVq-4R-s"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_titanic, y_titanic, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 579,
     "status": "ok",
     "timestamp": 1604482268917,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "Sq1dGaoK4R-v",
    "outputId": "8edddbef-1daa-47f7-a2ba-a517926e3794"
   },
   "outputs": [],
   "source": [
    "X_titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1604482271450,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "WsY1utdQ4R-y",
    "outputId": "d4496271-0b1b-44da-a86a-126655ec7dcd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_valid)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDy9JD2z4R-8"
   },
   "source": [
    "# Naive Bayes\n",
    "\n",
    "Intuition: Naive Bayes solves the classification problem by relying on Bayes's theorem, which is an equation describing the relationship of conditional probabilities of statistical quantities.\n",
    "In other words, what is the probability of a label, given some features, $P(L~|~{\\rm features})$\n",
    "\n",
    "It's naive because it makes naive assumptions about the distribution of the data.\n",
    "\n",
    "$ P(L~|~{\\rm features}) = \\frac{P({\\rm features}~|~L)P(L)}{P({\\rm features})} $\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "If we have only two possible labels (binary classification):\n",
    "$ \\frac{P(L_1~|~{\\rm features})}{P(L_2~|~{\\rm features})} = \\frac{P({\\rm features}~|~L_1)}{P({\\rm features}~|~L_2)}\\frac{P(L_1)}{P(L_2)} $\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "But how to compute $ P({\\rm features}~|~L_i) $ ?\n",
    "\n",
    "## Gaussian Naive Bayes\n",
    "\n",
    "Perhaps the easiest naive Bayes classifier to understand is Gaussian naive Bayes.\n",
    "In this classifier, the assumption is that data from each label is drawn from a simple Gaussian distribution.\n",
    "Imagine that you have the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 866,
     "status": "ok",
     "timestamp": 1604482355403,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "WDc_5dai4R_A",
    "outputId": "d151f9bf-5c72-4673-df64-1e0209e018ea"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(100, 2, centers=2, random_state=2, cluster_std=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=70, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTcxCyoS4R_B"
   },
   "source": [
    "One extremely fast way to create a simple model is to assume that the data is described by a Gaussian distribution with no covariance between dimensions.\n",
    "This model can be fit by simply finding the mean and standard deviation of the points within each label, which is all you need to define such a distribution.\n",
    "The result of this naive Gaussian assumption is shown in the following figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUF-p0aT4R_D"
   },
   "source": [
    "![image](https://drive.google.com/uc?export=view&id=14P1QVJIQohKvYBHUnKxHW7utSPVgW3N1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CG1PY01f4R_D"
   },
   "source": [
    "The ellipses here represent the Gaussian generative model for each label, with larger probability toward the center of the ellipses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6TcTjfQ4R_E"
   },
   "source": [
    "This procedure is implemented in Scikit-Learn's `sklearn.naive_bayes.GaussianNB` estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1604482390089,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "byGzKyrH4R_F",
    "outputId": "29b09731-6562-473d-8958-f2c6553aaafd"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzzA2kiw4R_I"
   },
   "source": [
    "Generate some data and predict the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1262,
     "status": "ok",
     "timestamp": 1604482408067,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "rMY1ETKY4R_I"
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "\n",
    "Xnew = [-6, -14] + [14, 18] * rng.random_sample((5000, 2))\n",
    "\n",
    "ynew = model.predict(Xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6XGakfT4R_L"
   },
   "source": [
    "Now we can plot this new data to get an idea of where the decision boundary is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 1584,
     "status": "ok",
     "timestamp": 1604482448152,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "k6myoLIl4R_M",
    "outputId": "a0844529-5f7f-4772-eb33-ae0cfd48b8cf"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=70, cmap='RdBu',alpha=1)\n",
    "lim = plt.axis()\n",
    "\n",
    "plt.scatter(Xnew[:, 0], Xnew[:, 1], c=ynew, s=20, cmap='RdBu', alpha=0.1)\n",
    "plt.axis(lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYAiqvcS4R_O"
   },
   "source": [
    "### When to use Naive Bayes\n",
    "\n",
    "Because naive Bayesian classifiers make such stringent assumptions about data, they will generally not perform as well as a more complicated model.\n",
    "That said, they have several advantages:\n",
    "* They are extremely fast for both training and prediction\n",
    "* They provide straightforward probabilistic prediction\n",
    "* They are often very easily interpretable\n",
    "* They have very few (if any) tunable parameters\n",
    "* These advantages mean a naive Bayesian classifier is often a good choice as an initial baseline classification.\n",
    "If it performs suitably, then congratulations: you have a very fast, very interpretable classifier for your problem. If it does not perform well, then you can begin exploring more sophisticated models, with some baseline knowledge of how well they should perform.\n",
    "\n",
    "Naive Bayes classifiers tend to perform especially well in one of the following situations:\n",
    "* When the naive assumptions actually match the data (very rare in practice)\n",
    "* For very well-separated categories, when model complexity is less important\n",
    "* For very high-dimensional data, when model complexity is less important\n",
    "\n",
    "The last two points seem distinct, but they actually are related: as the dimension of a dataset grows, it is much less likely for any two points to be found close together (after all, they must be close in every single dimension to be close overall).\n",
    "This means that clusters in high dimensions tend to be more separated, on average, than clusters in low dimensions, assuming the new dimensions actually add information.\n",
    "For this reason, simplistic classifiers like naive Bayes tend to work as well or better than more complicated classifiers as the dimensionality grows: once you have enough data, even a simple model can be very powerful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4-4GXJZ4R_Q"
   },
   "source": [
    "# k Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCtbTlUb4R_Q"
   },
   "source": [
    "k Nearest Neighbors is one of the simplest learning strategies.\n",
    "Given a new, unknown observation, look up in your reference database which ones have the closest features and assign the predominant class.\n",
    "\n",
    "A big disadvantage is that you need to store the entire *training* set (it's not actually training since you just keep the values around)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1604482700327,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "nZ6-AIuu4R_R"
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "\n",
    "iris = datasets.load_iris() # just another way to load the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ucpq9bC_4R_T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 910,
     "status": "ok",
     "timestamp": 1604482705524,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "RBIV5PHW4R_U",
    "outputId": "7b7b6fd7-68b1-46f9-c373-0d799e437815"
   },
   "outputs": [],
   "source": [
    "X_iris, y_iris = iris.data, iris.target\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_iris, y_iris, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_iris[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1604482722345,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "P4s296txO41Z",
    "outputId": "e1141ff2-0786-4bcc-c756-60cd3d053d12"
   },
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What kind of iris has 3cm x 5cm sepal and 4cm x 2cm petal?\n",
    "result = knn.predict([[3, 5, 4, 2]])\n",
    "print(result)\n",
    "print(iris.target_names[result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M21l0YEV4R_Z"
   },
   "source": [
    "Probabilistic predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1096,
     "status": "ok",
     "timestamp": 1604482775737,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "JR_3UGQg4R_d",
    "outputId": "71c000bd-fe77-436c-9076-2aefd3e6e215"
   },
   "outputs": [],
   "source": [
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1118,
     "status": "ok",
     "timestamp": 1604482778202,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "6cjGCYf84R_g"
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Create color maps for 3-class classification problem, as with iris\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "def plot_iris_knn(x):\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data[:, :2]  # we only take the first two features. We could\n",
    "                          # avoid this ugly slicing by using a two-dim dataset\n",
    "    y = iris.target\n",
    "\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=x)\n",
    "    knn.fit(X, y)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "    plt.xlabel('sepal length (cm)')\n",
    "    plt.ylabel('sepal width (cm)')\n",
    "    plt.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "executionInfo": {
     "elapsed": 1071,
     "status": "ok",
     "timestamp": 1604482856933,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "rO5WT-224R_l",
    "outputId": "9e9eff5a-0d4e-4670-8d9d-6f8367b9d058"
   },
   "outputs": [],
   "source": [
    "plot_iris_knn(x=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FlQlS4f4SA9"
   },
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZS2ze0E4SA-"
   },
   "source": [
    "Decision trees are extremely intuitive ways to classify or label objects: you simply ask a series of questions designed to zero-in on the classification.\n",
    "For example, if you wanted to build a decision tree to classify an animal, you could do the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcXnpOg14SA_"
   },
   "source": [
    "![image](https://drive.google.com/uc?export=view&id=13D_mcYQ1cVlB0xfjK2TCYk6eFqwS7pKq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gP2S1pCS4SA_"
   },
   "source": [
    "The binary splitting makes this extremely efficient: in a well-constructed tree, each question will cut the number of options by approximately half, very quickly narrowing the options even among a large number of classes.\n",
    "\n",
    "Decision Trees end up overfitting the data but we can do better if we combine multiple Decision Trees and average their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYzKnnnq4SBA"
   },
   "source": [
    "## Random Forests\n",
    "\n",
    "A Random Forest is an ensemble of Decision Trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the titanic dataset again\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_titanic, y_titanic, test_size=0.3) \n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xy8wT7pB4SBC"
   },
   "source": [
    "# References\n",
    "\n",
    "* https://github.com/jakevdp/PythonDataScienceHandbook\n",
    "* https://github.com/ipython-books/cookbook-2nd-code/blob/master/chapter08_ml/02_titanic.ipynb\n",
    "* https://github.com/ipython-books/cookbook-2nd/blob/master/chapter08_ml/02_titanic.md\n",
    "* https://www.kaggle.com/startupsci/titanic-data-science-solutions\n",
    "* https://datascienceplus.com/logistic-regression-with-python-using-titanic-data/\n",
    "* https://www.kaggle.com/mnassrib/titanic-logistic-regression-with-python\n",
    "* https://mashimo.wordpress.com/2018/03/31/logistic-regression-using-sklearn/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gYAiqvcS4R_O",
    "QYzKnnnq4SBA"
   ],
   "name": "07_machine_learning_2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
