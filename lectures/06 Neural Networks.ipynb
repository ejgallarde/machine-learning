{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSLAaUPhw6RN"
   },
   "source": [
    "# Introduction to Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hr1raXjw6Rb"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T19:59:37.925859Z",
     "start_time": "2021-09-14T19:59:37.425487Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2424,
     "status": "ok",
     "timestamp": 1604491282559,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "wjh8Ucs-w6Re",
    "outputId": "3873d2b6-6664-4f44-fff3-eb71acb8d62d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('retina')\n",
    "matplotlib.rcParams['figure.figsize'] = (12, 8)\n",
    "matplotlib.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xs9ji3mRw6Rq"
   },
   "source": [
    "# Artificial Neural Networks (ANNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSzyLYwdw6Ru"
   },
   "source": [
    "An Artificial Neural Network is a nesting of functions arranged in layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WB-EXJxZw6Rw"
   },
   "source": [
    "## What is a Neuron?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvGNMT0qw6Rz"
   },
   "source": [
    "![image](https://drive.google.com/uc?export=view&id=1qSVls_zidJ-nGcExfBHQrdEwD_xO_ZjR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPTisLu2w6R0"
   },
   "source": [
    "Linear function: $Wx + b$\n",
    "\n",
    "Non-linearity (activation function): $f(x)$\n",
    "\n",
    "Every neuron computes: $f(Wx + b)$\n",
    "\n",
    "A single neuron is a Linear Regression if specified without an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-loGyZOw6R3"
   },
   "source": [
    "![image](https://drive.google.com/uc?export=view&id=1SniRhePcgf4SBNKUBaFsU4VDjzo3Kz1V)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxE-gBo_w6R6"
   },
   "source": [
    "Hidden layers predict connections between inputs automatically.\n",
    "\n",
    "Deep Neural Networks (NNs) have more hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INu9hM4Ow6R9"
   },
   "source": [
    "![image](https://drive.google.com/uc?export=view&id=1pzhyOacSy7rzcOsMPzdaxVmOr0g5CCTF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXZmRAYFw6R_"
   },
   "source": [
    "## Why multiple layers?\n",
    "\n",
    "The intuition is that the network gradually makes relations with data from simple to complex.\n",
    "In each layer it tries to model a relation with the previous layer.\n",
    "\n",
    "Face recognition:\n",
    "Image -> Edges -> Face parts -> Faces -> Desired face\n",
    "\n",
    "Audio recognition:\n",
    "Audio -> Low level sound features -> Phonemes -> Words -> Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8JN8FKEw6SB"
   },
   "source": [
    "# Shallow or deep?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7PJzmkqw6SD"
   },
   "source": [
    "Deep > Shallow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B78ByQXDw6SE"
   },
   "source": [
    "## Is it similar to how our brain works?\n",
    "\n",
    "This is an over simplified analogy between a single brain neuron and NN unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyBqar5Ew6SF"
   },
   "source": [
    "## Activation Functions\n",
    "\n",
    "Popular functions:\n",
    "* `Sigmoid` $\\sigma (x) = {1 \\over{1 + e^{-x}}}$\n",
    "* `tanh`\n",
    "* Leaky ReLU, $Leaky ReLU(x) = max(0.1x, x)$\n",
    "* Rectified Linear Unit (ReLU), $ReLU(x) = max(0, x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T20:15:09.616436Z",
     "start_time": "2021-09-14T20:15:09.577450Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 1227,
     "status": "ok",
     "timestamp": 1603487757435,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -180
    },
    "id": "VIH3dDI6w6SG",
    "outputId": "b6678853-ae79-41b2-c5a1-8bae646763f8"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def leakyrelu(x):\n",
    "    return np.maximum(x, 0.1*x)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "x = np.linspace(-10, 10, num=50)\n",
    "ax[0, 0].plot(x, relu(x))\n",
    "ax[0, 0].set_title('relu(x)')\n",
    "ax[0, 0].grid(True)\n",
    "\n",
    "ax[0, 1].plot(x, leakyrelu(x))\n",
    "ax[0, 1].set_title('leakyrelu(x)')\n",
    "ax[0, 1].grid(True)\n",
    "\n",
    "ax[1, 0].plot(x, sigmoid(x))\n",
    "ax[1, 0].set_title('sigmoid(x)')\n",
    "ax[1, 0].grid(True)\n",
    "\n",
    "ax[1, 1].plot(x, tanh(x))\n",
    "ax[1, 1].set_title('tanh(x)')\n",
    "ax[1, 1].grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lobHW4aww6SO"
   },
   "source": [
    "### Why non-linear activation functions?\n",
    "\n",
    "If we remove the activation function, our algorithm would be linear.\n",
    "Stacking multiple linear functions together result in a linear function.\n",
    "The intuition here is that since our dataset is non-linear, we give the network the ability to learn non-linearities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTnc6Zb5w6SR"
   },
   "source": [
    "# More vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyMlT0a2w6ST"
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "* Number of hidden layers\n",
    "* Number of neurons in each layer\n",
    "* Learning rate\n",
    "* Activation functions\n",
    "* initialization of weights\n",
    "* batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUu66e04w6SV"
   },
   "source": [
    "## Weight initialization\n",
    "\n",
    "It's important to initialize the weights with values different than $0$, and not constant.\n",
    "\n",
    "There are multiple initialization strategies:\n",
    "* uniform/normal distributions\n",
    "* LeCun uniform/normal\n",
    "* Glorot/Xavier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyMMv_Vmw6SX"
   },
   "source": [
    "## Types of ANNs\n",
    "\n",
    "* Fully Connected NN, structured data\n",
    "* Convolutional Neural Networks (CNN), for Computer Vision\n",
    "* Recurrent Neural Networks (RNN), speech recognition, natural language processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z80QG-8sw6SZ"
   },
   "source": [
    "## Tensors\n",
    "\n",
    "A Tensor is a generalization of vectors and matrices to higher dimensions.\n",
    "It has a rank (number of dimensions):\n",
    "* 0, scalar, magnitude only\n",
    "* 1, vector, magnitude and direction\n",
    "* 2, matrix, table of numbers\n",
    "* 3, cube of numbers\n",
    "* n, n-dimensional array\n",
    "\n",
    "## Computational Graph\n",
    "\n",
    "Example from GoogLeNet (Inception v1)\n",
    "\n",
    "![image](https://drive.google.com/uc?export=view&id=1E-hbbTwb7cJb2-6Gy0vUXjgwiD908Ri7)\n",
    "\n",
    "\n",
    "## Forward/Backward Propagation\n",
    "\n",
    "Forward pass for inference\n",
    "\n",
    "Backward Propagation to optimize weights\n",
    "\n",
    "## Optimizer\n",
    "\n",
    "The optimizer specifies in which way the gradient of the loss will be used to update parameters.\n",
    "\n",
    "* SGD\n",
    "* RMSprop\n",
    "* Adam\n",
    "...\n",
    "\n",
    "\n",
    "## Loss function\n",
    "\n",
    "* Mean Squared Error (MSE)\n",
    "* Mean Absolute Error (MAE)\n",
    "* Categorical Crossentropy\n",
    "...\n",
    "\n",
    "\n",
    "## Epochs\n",
    "\n",
    "How many times the training will use the training data.\n",
    "\n",
    "## Batch/mini-batch size\n",
    "\n",
    "Batch size, how many samples to use for every iteration of the Optimizer.\n",
    "\n",
    "Ranges from small numbers (e.g. 1) to higher values (1024, 2048, etc).\n",
    "\n",
    "In general, the higher the number of samples in the batch, the faster the model converges and more accurate since the effectiveness of the optimization steps depends on the size of the batch.\n",
    "\n",
    "Since we want to use the entire training set during an epoch and most likely the dataset does not fit the CPU/GPU memory, we'll have to split it over multiple mini batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIoSykzEw6Sc"
   },
   "source": [
    "# Summary\n",
    "\n",
    "**Training** an Artificial Neural Networks boils down to minimizing a cost (loss) function by optimizing the parameters (weights) of the model.\n",
    "This is not an easy task since there can be milions of parameters to optimize.\n",
    "\n",
    "**The loss function** that is being minimized includes a sum, or a form of penalty over all of the training samples available.\n",
    "\n",
    "**The optimization** is commonly done using Stochastic Gradient Descent over batches of input data, until all the data has been used.\n",
    "\n",
    "**Epoch**. A complete cycle through all of the training data is called an **epoch**.\n",
    "The training (optimization) runs for a number of epoch until the loss function is minimized and the model has reached an accuracy level that is acceptable or it stopped improving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVAeZFomw6Se"
   },
   "source": [
    "# Popular Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6K5TVSBTw6Sf"
   },
   "source": [
    "* TensorFlow backed by Google\n",
    "* Keras High level API backed by Google\n",
    "* PyTorch backed by Facebook\n",
    "* Caffe2 backed by Facebook\n",
    "* Microsoft Cognitive Toolkit (CNTK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_RLYwmNw6Sh"
   },
   "source": [
    "# TensorFlow\n",
    "\n",
    "Backed by Google, Open Source (Apache 2.0 license), https://github.com/tensorflow/tensorflow\n",
    "\n",
    "Released in November, 2015.\n",
    "\n",
    "Has stable Python and C APIs.\n",
    "\n",
    "Mobile variant for Android, iOS: TensorFlow Lite.\n",
    "\n",
    "Backends for CPU, GPU (Nvidia CUDA, ROCm AMD, OpenCL/SYSCL), Google Tensor Processing Units (TPUs) ASICs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAnmJhN1w6Si"
   },
   "source": [
    "# Keras\n",
    "\n",
    "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano.\n",
    "\n",
    "It was developed with a focus on enabling fast experimentation.\n",
    "\n",
    "http://keras.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_YOXiI3w6Sk"
   },
   "source": [
    "# Linear Regression with Keras and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICJ4Mjmiw6Sm"
   },
   "source": [
    "The core data structure in Keras is a *model*, which is a way to organize layers.\n",
    "\n",
    "The simplest type of model is the `Sequential` model, a linear stack of layers.\n",
    "\n",
    "More complex architectures are also possible, check the **Keras functional API**.\n",
    "\n",
    "Let's define the simplest possible neural networks. It has 1 layer, and that layer has a single neuron, so the input shape is just one value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6647,
     "status": "ok",
     "timestamp": 1604493348383,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "WlRSsg3Hw6Sn"
   },
   "outputs": [],
   "source": [
    "# check doc, you can directly add the layers here\n",
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvItFnVcw6Ss"
   },
   "source": [
    "Adding layers is done with the `add()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1013,
     "status": "ok",
     "timestamp": 1604493351960,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "L634V9RUw6Sv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1604493353885,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "sYoLLxAiw6Sz"
   },
   "outputs": [],
   "source": [
    "mylayer = keras.layers.Dense(units=1, input_shape=[1])\n",
    "\n",
    "model.add(mylayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXDYW21Cw6S4"
   },
   "outputs": [],
   "source": [
    "# equivalent approach\n",
    "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSgIp-Ifw6TC"
   },
   "source": [
    "Now we need to compile the network, but in order to do that, we need to specify an optimizer and a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1001,
     "status": "ok",
     "timestamp": 1604493398166,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "-utDHZDTw6TD"
   },
   "outputs": [],
   "source": [
    "# All parameter gradients will be clipped to a maximum norm of 1.\n",
    "sgd = keras.optimizers.SGD(learning_rate=0.01, clipnorm=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1068,
     "status": "ok",
     "timestamp": 1604493417175,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "FPy0KRsYw6TI"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 806,
     "status": "ok",
     "timestamp": 1604493418086,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "VzhaHnilw6TM",
    "outputId": "efad6dea-163c-48d8-afaf-af21edc23eb1"
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "# see the number of parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPorXDTlw6TU"
   },
   "source": [
    "## Example data\n",
    "\n",
    "Let's assume that our function is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1320,
     "status": "ok",
     "timestamp": 1604493460425,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "3NuwTH6nw6TV"
   },
   "outputs": [],
   "source": [
    "def myfunc(x):\n",
    "    return 3 * x - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 1111,
     "status": "ok",
     "timestamp": 1604493462876,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "rJkN8UoEw6Tc",
    "outputId": "f09d5dc7-1a20-475d-a573-6c2fca90a424"
   },
   "outputs": [],
   "source": [
    "# X = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "X = np.linspace(-1, 20, 100)\n",
    "y = myfunc(X).astype(float)\n",
    "\n",
    "plt.plot(X, y)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ufx0yh_6w6Tj"
   },
   "source": [
    "## Training the network\n",
    "\n",
    "The process of training the neural network, where it learns the relationship between the Xs and Ys is in the `model.fit` call.\n",
    "\n",
    "This involves a loop in which the loss function and the optimizer are used to optimize the network over *epoch* number of times. The prints that we get allow us to baby sit the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1324,
     "status": "ok",
     "timestamp": 1604493470237,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "_75irf9uciyO",
    "outputId": "4dcbda1e-c61d-45cb-9f30-4b5391b5b1fc"
   },
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8658,
     "status": "ok",
     "timestamp": 1604493488956,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "zDO69tXYw6Tl",
    "outputId": "55311369-4461-4469-f615-52b06ee3799c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(X, y,\n",
    "                    epochs=200,\n",
    "                    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1066,
     "status": "ok",
     "timestamp": 1604493523776,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "UKRagktEw6Ts",
    "outputId": "5b6ac985-e14c-440a-efd3-a8fbf7b17716"
   },
   "outputs": [],
   "source": [
    "print(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3U4MTW4w6Ty"
   },
   "source": [
    "Now we have a model that has been trained. We can use this model to predict the values on previously unseen data using `model.predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 1081,
     "status": "ok",
     "timestamp": 1604493528996,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "UD0i5gjAw6Tz",
    "outputId": "71bf6756-17a9-410c-a187-a766b496093b"
   },
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzEnY74Bw6T2"
   },
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test = np.array([0, 10])\n",
    "print(model.predict(x_test))\n",
    "print(f\"True values: {myfunc(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1391,
     "status": "ok",
     "timestamp": 1604493567148,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "Cg8mdqzuw6T7",
    "outputId": "5b977901-f599-4014-b4e8-31001cf94b2a"
   },
   "outputs": [],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1443,
     "status": "ok",
     "timestamp": 1604493570032,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "Okph6ADAw6UD",
    "outputId": "b90f7d64-103d-44d1-e1fd-eb82e1cd74c2"
   },
   "outputs": [],
   "source": [
    "l1 = model.layers[0]\n",
    "\n",
    "print(type(l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1013,
     "status": "ok",
     "timestamp": 1604493573934,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "YLuM9tfJw6UO",
    "outputId": "c5e04b7e-1006-4c75-d0f9-2871ed9d69ae"
   },
   "outputs": [],
   "source": [
    "l1.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ka9PWnjaw6US"
   },
   "source": [
    "# Going Deeper with a Computer Vision Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4WgpIihw6UT"
   },
   "source": [
    "Now that we've seen how to model the relationship between a single feature and a single output, let's try something more difficult.\n",
    "\n",
    "The Fashion MNIST dataset contains 60000 examples, and a test set of 10000 examples.\n",
    "Each example is a 28x28 grayscale image (i.e. 28,28,1) associated with a label from 10 classes.\n",
    "\n",
    "Classes:\n",
    "* 0 T-shirt/top\n",
    "* 1 Trouser\n",
    "* 2 Pullover\n",
    "* 3 Dress\n",
    "* 4 Coat\n",
    "* 5 Sandal\n",
    "* 6 Shirt\n",
    "* 7 Sneaker\n",
    "* 8 Bag\n",
    "* 9 Ankle boot \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVYzDdikw6UU"
   },
   "source": [
    "The Fashion MNIST dataset is available directly using `keras.dataset` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1118,
     "status": "ok",
     "timestamp": 1604493941395,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "NnnMxRW8w6UV"
   },
   "outputs": [],
   "source": [
    "# notice we get both training and test images\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIYxu-3rw6UY"
   },
   "source": [
    "Remember, these are images, hence we're dealing with pixels organized on rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1330,
     "status": "ok",
     "timestamp": 1604493613774,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "SZGAKPxOw6UZ",
    "outputId": "9246aacd-df05-4fea-b8f6-cba79d033582"
   },
   "outputs": [],
   "source": [
    "print(training_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 671,
     "status": "ok",
     "timestamp": 1603489375128,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -180
    },
    "id": "YzmVwI-Gw6Ue",
    "outputId": "1bff1c7f-bc1e-4b38-bba9-3024ad761e9d"
   },
   "outputs": [],
   "source": [
    "28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 996,
     "status": "ok",
     "timestamp": 1604493623400,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "sBYIeEdew6Ui",
    "outputId": "cbc81a1a-cd20-4bec-d176-34829864272e"
   },
   "outputs": [],
   "source": [
    "training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 795,
     "status": "ok",
     "timestamp": 1604493625204,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "xdx0gzwxw6Uk",
    "outputId": "abbd1d98-534c-4e91-83fc-4dbc62d5cb3c"
   },
   "outputs": [],
   "source": [
    "a_sample = training_images[0]\n",
    "print(a_sample.shape)\n",
    "print(a_sample[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2780,
     "status": "ok",
     "timestamp": 1604493634900,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "etzh-eYPw6Up",
    "outputId": "8f07b080-b5c5-41e4-bbec-d858cf2f9156",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    index = np.argwhere(training_labels == i).ravel()\n",
    "    first_idx = index[0]\n",
    "    plt.figure()\n",
    "    plt.imshow(training_images[first_idx], cmap='gray')\n",
    "    plt.title('class {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDQecg21w6Us"
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7z_Uertw6Ut"
   },
   "source": [
    "Notice that all of the values are between 0 and 255.\n",
    "\n",
    "Training Neural Networks is easier if all values are between $[0, 1]$ or $[-1, 1]$.\n",
    "This process is called normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 972,
     "status": "ok",
     "timestamp": 1604493945678,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "ImE8dW87w6Ut",
    "outputId": "3b210ab3-09e9-4bdb-8dee-3f79860d3a2b"
   },
   "outputs": [],
   "source": [
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "training_images = training_images.reshape((training_images.shape[0], training_images.shape[1] * training_images.shape[2]))\n",
    "test_images = test_images.reshape((test_images.shape[0], test_images.shape[1] * test_images.shape[2]))\n",
    "\n",
    "print(training_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fz8DuewEw6Uw"
   },
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1604493950354,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "MtTNKFeUw6Uz"
   },
   "outputs": [],
   "source": [
    "# ON TRAINING DATA\n",
    "mean = np.mean(training_images)\n",
    "stddev = np.std(training_images)\n",
    "\n",
    "training_images = (training_images - mean) / stddev\n",
    "test_images = (test_images - mean) / stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaZi2Fo2w6U0"
   },
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHg80ZJhw6U1"
   },
   "source": [
    "Let's create a model which has two layers:\n",
    "* One hidden layer 128 units (neurons)\n",
    "* The output layer with 10 units since we're doing a classification problem with 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 997,
     "status": "ok",
     "timestamp": 1604494215105,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "seX0fi9tw6U2"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(128, input_shape=(784, ), activation='relu'), \n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 952,
     "status": "ok",
     "timestamp": 1604494216776,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "JHGxrBxFw6VI"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "#model.add(keras.layers.Dense(128, input_shape=(784, ), activation='relu'))\n",
    "model.add(keras.layers.Dense(128, input_shape=(784, ), activation=keras.activations.relu))\n",
    "model.add(keras.layers.Dense(10, activation=keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zgbvlz-3w6VM"
   },
   "source": [
    "## Softmax?\n",
    "\n",
    "We want the outputs of the output layer to be probabilities between $[0, 1]$.\n",
    "\n",
    "As we saw, the output of the units depends on the function $wx + b$ which can output any real value.\n",
    "Softmax takes $K$ real numbers, and normalizes them into a probability distribution consisting of K probabilities.\n",
    "This basically means that all output will add up to 1, and they can be interpreted as probabilities.\n",
    "Larger input components will correspond to larger probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 983,
     "status": "ok",
     "timestamp": 1604494219852,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "thw_VldOw6VN"
   },
   "outputs": [],
   "source": [
    "# sparse_categorical_crossentropy\n",
    "# categorical_crossentropy\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(optimizer = optimizer,\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['acc'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1097,
     "status": "ok",
     "timestamp": 1604494230283,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "WmYxupM-w6VR"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['acc'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 954,
     "status": "ok",
     "timestamp": 1604494236453,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "3uQ0qqaRw6VT",
    "outputId": "a5dacbb2-8bd2-426b-cd37-44fa6cbdd975"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    training_images,\n",
    "    training_labels,\n",
    "    validation_split=0.1,\n",
    "    epochs=50,\n",
    "    workers=1,\n",
    "    shuffle=False,\n",
    "    batch_size=2048*8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbtPpq_Aw6Va"
   },
   "source": [
    "Once the training is done, you'll see the accuracy value at the end of the final epoch.\n",
    "\n",
    "Remember, this accuracy value is on the training set, so it's not particularly fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "executionInfo": {
     "elapsed": 1935,
     "status": "ok",
     "timestamp": 1603490658848,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -180
    },
    "id": "khFD42uJw6Va",
    "outputId": "f6ea1788-fb53-41c1-9bae-6a0de2f0f9b9"
   },
   "outputs": [],
   "source": [
    "history = model.fit(training_images, training_labels,\n",
    "    validation_split=0.1,\n",
    "    epochs=10,\n",
    "    workers=1,\n",
    "    shuffle=False,\n",
    "    batch_size=2048*16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZql5gNZw6Vc"
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "executionInfo": {
     "elapsed": 1185,
     "status": "ok",
     "timestamp": 1604494261483,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "8IIny7_gw6Ve",
    "outputId": "675ce739-ba3b-4030-e7d9-ccb1d2d7d82e"
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1497,
     "status": "ok",
     "timestamp": 1604495020217,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "cI8e1ugUw6Vl",
    "outputId": "665d0037-f37e-4291-ecef-2c137af30d64"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "784 * 128 + 128 + 10 * 128 + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nd-KObc5w6Vo"
   },
   "source": [
    "Evaluate the network on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1017,
     "status": "ok",
     "timestamp": 1604495028406,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "0CxG2kT0w6Vo",
    "outputId": "b7f4c7e1-5a63-4729-cdb0-bc2531792ab0"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_labels,\n",
    "    batch_size=2048*16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2464,
     "status": "ok",
     "timestamp": 1604495055740,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "XexJu4W0UwCb",
    "outputId": "e5ae52be-72ff-440f-f5ea-cea91bae5b68"
   },
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    index = np.argwhere(test_labels == i).ravel()\n",
    "    first_idx = index[0]\n",
    "    plt.figure()\n",
    "    plt.imshow(test_images.reshape(10000,28,28)[first_idx], cmap='gray')\n",
    "    plt.title('True class : {}, Predicted class : {}'.format(i, np.argmax(model.predict(test_images[first_idx,np.newaxis]))))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7714,
     "status": "ok",
     "timestamp": 1604495096309,
     "user": {
      "displayName": "Machine Learning Trainer",
      "photoUrl": "",
      "userId": "14920981527372025521"
     },
     "user_tz": -120
    },
    "id": "mDZjTZ1AVfbz",
    "outputId": "e0293893-9f45-4391-deed-9c5401ef8872"
   },
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    index = np.argwhere(test_labels == i).ravel()\n",
    "    t = True\n",
    "    j = 0\n",
    "    while t==True:\n",
    "        first_idx = index[j]\n",
    "        if np.argmax(model.predict(test_images[first_idx,np.newaxis])) != i:\n",
    "            t = False\n",
    "        j += 1\n",
    "    plt.figure()\n",
    "    plt.imshow(test_images.reshape(10000,28,28)[first_idx], cmap='gray')\n",
    "    plt.title('True class : {}, Predicted class : {}'.format(i, np.argmax(model.predict(test_images[first_idx,np.newaxis]))))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks for image reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, _), (X_test, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = X_train.shape[1:]\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0, ...], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data(X_train):\n",
    "    image_shape = X_train.shape[1:]\n",
    "    \n",
    "    # Neural networks work best with normalized data\n",
    "    X_train_normalized = X_train / 255\n",
    "    # Since our goal is to reconstruct the original images, the reference is the same array\n",
    "    X_reference = X_train_normalized.reshape(-1, image_shape[0] * image_shape[1])\n",
    "    \n",
    "    return X_train_normalized, X_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized, X_reference = prepare_train_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(X_train_normalized, X_reference, hidden_layer_size):\n",
    "    image_shape = X_train_normalized.shape[1:]\n",
    "    \n",
    "    # Define the neural network architecture\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "        tf.keras.layers.Dense(image_shape[0] * image_shape[1], activation='relu'),\n",
    "    ])\n",
    "    \n",
    "    # Choose an optimizer and a metric\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "    )\n",
    "    \n",
    "    # Train the model on data\n",
    "    model.fit(\n",
    "        X_train_normalized,\n",
    "        X_reference,\n",
    "        epochs=10,\n",
    "        batch_size=64)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_LAYER_SIZE = image_shape[0] * image_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(X_train_normalized, X_reference, HIDDEN_LAYER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_image(model, img):\n",
    "    image_shape = img.shape\n",
    "    \n",
    "    # Normalize the input image\n",
    "    img_normalized = img / 255\n",
    "    img_normalized = img_normalized.reshape(1, image_shape[0], image_shape[1])\n",
    "\n",
    "    # Use the model to create a reconstruction\n",
    "    reconstructed_img_normalized = model.predict(img_normalized)\n",
    "    \n",
    "    # Undo the normalization for plotting purposes\n",
    "    reconstructed_img_normalized = reconstructed_img_normalized.reshape(image_shape)\n",
    "    reconstructed_img = reconstructed_img_normalized * 255\n",
    "    \n",
    "    return reconstructed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_reconstruction(model, img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title('Original image')\n",
    "    plt.show()\n",
    "   \n",
    "    reconstructed_img = reconstruct_image(model, img)\n",
    "\n",
    "    plt.imshow(reconstructed_img, cmap='gray')\n",
    "    plt.title('Reconstructed image')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_ID = 42\n",
    "img = X_test[IMG_ID, ...]\n",
    "\n",
    "compare_reconstruction(model, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibNkuhFqw6Vz"
   },
   "source": [
    "# Resources\n",
    "\n",
    "* https://github.com/lmoroney/dlaicourse/blob/master/Course%201%20-%20Part%202%20-%20Lesson%202%20-%20Notebook.ipynb\n",
    "* https://github.com/fonnesbeck/Bios8366/blob/master/notebooks/Section7_1-Introduction-to-Tensorflow.ipynb\n",
    "* https://github.com/fonnesbeck/Bios8366/blob/master/notebooks/Section7_2-Neural-Networks.ipynb\n",
    "* https://github.com/fonnesbeck/Bios8366/tree/master/notebooks\n",
    "* https://github.com/mbadry1/DeepLearning.ai-Summary/tree/master/1-%20Neural%20Networks%20and%20Deep%20Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EH5dA5VTFxax"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "B78ByQXDw6SE",
    "lobHW4aww6SO",
    "JyMlT0a2w6ST",
    "tUu66e04w6SV",
    "DyMMv_Vmw6SX",
    "z80QG-8sw6SZ"
   ],
   "name": "08_deep_learning_1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
